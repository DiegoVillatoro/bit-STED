# bit-STED
Object Detection Model

Related paper: <b>Bit-STED: A Lightweight Transformer for Accurate Agave Counting with UAV Imagery </b>

This study presents bit-STED, a novel and simplified transformer encoder architecture for efficient agave plant detection using unmanned aerial vehicle (UAV) imagery, and a specialized algorithm for accurate plant counting in orthophotos generated by UAV overflights. The bit-STED model features a simplified backbone integrating a two-scale transformer, Dual Patch Norm (DPN) with activation, bitnet quantization, multiquery attention (GQA), and circular bounding box (C-Bbox) shape predictions. This architecture is designed for resource-efficient object detection in agricultural fields with limited computational capabilities. The counting algorithm addresses the challenges of counting plants across overlapping image tiles by employing Non-Maximum Suppression based on Fractional Area (NMS-FA), effectively managing plants spanning multiple tiles. Experimental results demonstrate that the bit-STED model exhibits improved performance in agave plant detection and counting compared to baseline models, achieving a competitive F1 score. The bit-STED nano model is barely an eighth of the size of the smaller Yolo-v8 model, with decreased trainable parameters evident in its compact size, potentially enabling migration to platforms better suited to field requirements. This study highlights the potential of a simplified transformer architecture for efficient and precise agave monitoring in resource-constrained agricultural settings. 

<p>Data can be available on request</p>
The data of the images are tif files with the multispectral data of the image
The image size is 224x224

DSTAdam optimizer used in training model was obtained from 
https://github.com/kunzeng/DSTAdam
